{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos para NLP \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- La siguiente palabra más probable\n",
    "Construya una función que utilizando el archivo big.txt del tutorial de Norvig ([Tutorial](http://norvig.com/spell-correct.html)), estime la siguiente palabra más probable dada una anterior. Formalmente, dada una palabra $w_i$, la funcion debe calcular $w_{i+1}$ tal que: \n",
    "\n",
    "$$ w_{i+1} = \\arg \\max_{w_{i+1}} P(w_{i+1}|w_i) $$\n",
    "\n",
    "Notas: 1) Podemos asumir que ambas palabras dadas siempre existen en la colección. 2) Se requiere una función P similar a la de Norvig, pero que también estime la probabilidad condicional de cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word(word):\n",
    "    # your code here\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explica tu estrategia, muestre que su propuesta funciona con diferentes ejemplos, y discuta el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- The hangman\n",
    "\n",
    "Diseñe una funcion que sea capaz de encontrar los caracteres faltantes de una palabra. La función debe trabajar como sigue:\n",
    "\n",
    "```\n",
    ">>> hangman(\"pe_p_e\")\n",
    "'people'\n",
    "\n",
    ">>> hangman(\"phi__sop_y\")\n",
    "'philosophy'\n",
    "\n",
    ">>> hangman(\"si_nif_c_nc_\")\n",
    "'significance'\n",
    "\n",
    ">>> hangman(\"kn__l_d_e\")\n",
    "'knowledge'\n",
    "\n",
    ">>> hangman(\"inte_r_ga_i_n\")\n",
    "'interrogation'\n",
    "```\n",
    "\n",
    "### Tips y Consideraciones: \n",
    "\n",
    "1) De preferencia adapte o extienda las estrategias del tutorial de Norvig discutidas en clase: [Tutorial](http://norvig.com/spell-correct.html)\n",
    "\n",
    "2) La función debe poder tratar con hasta 4 caracteres desconocidos en palabras de longitud arbitraria. Además la función debe trabajar en tiempo razonable (máximo 1 minuto en una laptop).\n",
    "\n",
    "3) También puede utilizar cualquier otro algoritmo para obtener distancias de edición (e.g., [Levenshtein](https://es.wikipedia.org/wiki/Distancia_de_Levenshtein)) o bien para encontrar subcadenas (e.g., [Karp Rabin](https://es.wikipedia.org/wiki/Algoritmo_Karp-Rabin), [Aho-Corasick](https://es.wikipedia.org/wiki/Algoritmo_de_b%C3%BAsqueda_de_cadenas_Aho-Corasick)). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangman(word):\n",
    "    ### your code here\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explica tu estrategia, muestre que su propuesta funciona con diferentes ejemplos, y discuta el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Corrección ortográfica simple\n",
    "\n",
    "Funciones de ayuda para leer el texto en: i) un string y ii) una lista de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.txt\n",
      "10.txt\n",
      "2.txt\n",
      "3.txt\n",
      "4.txt\n",
      "5.txt\n",
      "6.txt\n",
      "7.txt\n",
      "8.txt\n",
      "9.txt\n",
      "10 files loaded.\n",
      "['scientists', 'witness', 'huge', 'cosmic', 'crash', 'find', 'origins', 'of', 'gold', 'even']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# simple extraction of words\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# siple loading of the documents\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "def get_texts_from_catdir(cat_dir):\n",
    "    texts = []\n",
    "    TARGET_DIR = cat_dir # \"./target\"\n",
    "    for f_name in sorted(os.listdir(TARGET_DIR)):\n",
    "        f_path = os.path.join(TARGET_DIR, f_name)\n",
    "        #print(f_name)\n",
    "        #print(f_path)\n",
    "        f = open(f_path, \"r\",  encoding=\"utf8\")\n",
    "        print(f_name)\n",
    "        texts += [f.read()]                \n",
    "        f.close()\n",
    "    print(\"%d files loaded.\" % len(texts))\n",
    "    return texts\n",
    "\n",
    "# Load the RAW text \n",
    "target_txt = get_texts_from_catdir(\"./target\")\n",
    "\n",
    "# Print first 10 words in document0\n",
    "print(words(target_txt[0])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Construya un corrector ortográfico simple y generador de candidatos.\n",
    "\n",
    "Descargue los archivos de apoyo para esta pregunta de [aquí](https://github.com/fagonzalezo/dl-tau-2017-2/blob/master/assign2_q2_files.zip). \n",
    "Descomprima el archivo y ponga su contenido en la raíz de su notebook. En este archivo se le proporcionan 10 noticias en el directorio \"target\" en las cuales se han introducido algunos errores. Además, para evaluar a su corrector también tiene el directorio golden que contiene el texto correcto. Siéntete libre de adaptar y/o extender el código de Norvig para tener un corrector básico y completar esta parte de la tarea. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Mezclar WORDS[word] con DIC_WORDS_IN_NEWS\n",
    "\n",
    "Genere un solo diccionario/vocabulario global mezclando los diccionarios DIC_WORDS_IN_NEWS y WORDS y sus frecuencias. Asegurese que si una palabra de un diccionario ya está en el otro, entonces el diccionario resultante contendrá las suma de las frecuencias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('WORDS_IN_NEWS.txt', 'r') as infile:\n",
    "    WORDS_IN_NEWS = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dic(words_dic, words_in_news_dic):\n",
    "    '''\n",
    "    words_dic: for example WORDS\n",
    "    words_in_news_dic: for example WORDS_IN_NEWS\n",
    "    Returns: Merged dictionary merged_word_dic\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    return merged_word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = merge_dic(WORDS, WORDS_IN_NEWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Detecte las palabras mal escritas en las noticias\n",
    "\n",
    "Instrucciones: Cree una funcion que dadas las palabras de un texto, regrese una lista conteniendo las tuplas de cada palabra que no está bien escrita y su lista de palabras candidatas para corregir. Se espera que la funcion trabaje con palabras fuera del vocabulario en el diccionario y sea capaz de generar posibles candidatos de reemplazo. Sientase libre de adaptar código del tutorial de Norvig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def misspelled_and_candidates(target_words):\n",
    "    '''\n",
    "    target_words: a text with possible misspellings represented as a list of words\n",
    "    Returns: list of tuples of the form [(\"misspelled-word-1\", [\"candidate-word-1_1\", \"candidate-word-1_2\"]), ...]\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    return misspelled_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example call to print the output. Target_txt[0] is the raw data from file 0.\n",
    "print(misspelled_and_candidates(words(target_txt[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print misspelled words and candidates for each document in target_txt list\n",
    "for text in target_txt:\n",
    "    print(misspelled_and_candidates(words(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Corrección completa\n",
    "\n",
    "Combine el uso de su función next_word (de la primera parte de esta tarea) con su generador de candidatos, para diseñar una estrategia que realice una corrección ortográfica completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_correction(input_text):\n",
    "    '''\n",
    "    input_text: a text with possible misspellings represented as a list of words\n",
    "    Returns: the text with corrected misspellings\n",
    "    '''\n",
    "    # Your code goes here\n",
    "    return corrected_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the correction to each target text\n",
    "corrected_txt = []\n",
    "for t_txt in target_txt:\n",
    "    corrected_txt += [spell_correction(words(t_txt))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explica tu estrategia, muestre que su propuesta funciona con diferentes ejemplos, y discuta el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu explicación y discusión va aquí!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Evalué a su corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_errors(corrected_text, reference_text):\n",
    "    if len(corrected_text) != len(reference_text):\n",
    "        print (\"The length of the lists does not match!\")\n",
    "        return\n",
    "    \n",
    "    errors = 0\n",
    "    for corrected_word, reference_word in zip(corrected_text, reference_text):\n",
    "        if corrected_word != reference_word:\n",
    "            errors += 1\n",
    "            \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare errors before and after correction\n",
    "# Ideally errors after correction should be 0, but they depend on your strategy. We will evaluate this part \n",
    "# with a held out set of text. \n",
    "\n",
    "golden_txt = get_texts_from_catdir(\"./golden\")\n",
    "errors_before=0\n",
    "errors_after=0\n",
    "for t_txt, g_txt, c_txt in zip(target_txt, golden_txt, corrected_txt):\n",
    "    errors_before += number_of_errors(words(t_txt), words(g_txt))\n",
    "    errors_after += number_of_errors(words(c_txt), words(g_txt))\n",
    "print(\"Total errors before correction:\", errors_before)\n",
    "print(\"Total errors after correction:\", errors_after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
